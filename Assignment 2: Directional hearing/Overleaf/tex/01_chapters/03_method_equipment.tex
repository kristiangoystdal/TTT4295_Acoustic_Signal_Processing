\chapter{Method and Equipment}
\label{ch:method_equipment}

For all tasks in this assignment, Python is used as the programming language. The code is organized into separate files for clarity and modularity. The main script, \texttt{main.py}, orchestrates the execution of the different tasks by calling functions defined in other files. The variables for head radius, speed of sound, and sampling frequency are defined in \texttt{main.py} and passed as parameters to the functions. These are the same for all tasks to ensure consistency, and is set to a head radius of \( a = 0.09~\mathrm{m} \), a speed of sound \( c = 343~\mathrm{m/s} \), and a sampling frequency of \( f_s = 44{,}100~\mathrm{Hz} \).

\section{Task 1: HRIR Model}
\label{sec:task1}

The HRIR model is implemented in Python as described in \autoref{sec:hrir}. The ITD for a given angle of incidence \( \theta \) is calculated using the Woodworth formula (\autoref{eq:woodworth}), which gives the time delay between the two ears in seconds. This delay is then converted to an integer sample delay based on the sampling frequency \( f_s \).

The HRIR for each ear is represented as a discrete impulse (delta function), with the ear closer to the sound source receiving the impulse at sample~0, and the opposite ear receiving it after the calculated delay. This models the difference in arrival time of a sound wave between the two ears.

The code listing for this function is shown in \autoref{lst:hrir}.

\section{Task 2: HRTF Frequency Response}
\label{sec:task2}

To calculate the HRTF frequency response, the formula for the HRTF of a rigid sphere is implemented as described in \autoref{eq:hrtf}. The HRTF is computed for both the left and right ears based on the angle of incidence \( \theta \).

The frequency vector is generated using a Fast Fourier Transform (FFT) size of \( n_{\text{fft}} = 512 \). The resulting frequency responses for both ears are calculated and can be visualized using plots. The code listing for this function is shown in \autoref{lst:hrtf}.

\section{Task 3: HRTF IIR Filter}
\label{sec:task3}

The coefficients for the IIR filter are derived using the bilinear transform as described in \autoref{sec:hrtf} and \autoref{app:bilinear}. These coefficients are then used to implement the filter in Python in \autoref{sec:task4} later.

The code listing for this function is shown in \autoref{lst:hrtfirr}.

\section{Task 4: Combined Model}
\label{sec:task4}

The combined model integrates IDT from \autoref{sec:task1} with the frequency-domain filtering from the HRTF IIR coefficients derived in \autoref{sec:task3}. This combination creates a complete Head-Related Impulse Response that includes both the interaural time difference and the spectral shaping caused by the head.

In the implementation, the IDT for each ear is convolved with the corresponding HRTF IIR filter to create a complete model of the head-related transfer function.

These transfer functions can be used to filter audio signals, simulating how a sound would be perceived from a specific direction for both ears.

The code listing for this function is shown in \autoref{lst:combined}.

\section{Task 5: Sound Demonstration}




\section{Equipment and Software}
\section{Verification and Visualization}
